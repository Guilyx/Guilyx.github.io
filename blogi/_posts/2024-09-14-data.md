Üks suurimaid saavutusi ning kindlasti just see saavutus, mis mind ennast CERN-i puhul enim hämmastas oli puhtalt see andmete kogus, mida nende eksperimendid toodavad. Ja ega neid pelgalt toodeta, need tuleb ju ka programmidest läbi jooksutada ja seejärel hoiustada. 
Sellel teemal oli kõige entusiastlikum rääkima Markus, kes oli üks neist, kes arendas välja algse ATLASE tarkvara (täpsemini *data acquisition system*i). Just Markuse tõttu kasutasime ka meie ATLASe tarkvara. 
Alustuseks ära juba nördimusttekitav fakt: kuigi CERN-is toimuv on arvutuslikult väga mahukas, jääb see siiski alla näiteks Amazonile või Facebookile. Sellest hoolimata räägime me mitte terabaitidest vaid lausa petabaidist andmetest, mis tekib LHC neljas eksperimendis ühes sekundis. Kuidas siuke number üldse kokku tuleb? Alustuseks toimetatakse LHC eksperimentides nanosekundi skaaladel (ATLAS töötab nt 25ns akendega). Teiseks on mitme laohoone jagu maa-alust ruumi tikitud täis erinevate detektoritega, millel igaühel on veel omakorda mitu väljundit. Näiteks meie vägagi primitiivses eksperimendis oli kasutusel 53 erinevat väljundit.  
Igatahes, hullumeelsed lood. Nende andmete käitlemiseks on CERN-il olemas omaenda pilvepõhine failide salvestamise teenus CERNbox. Lisaks oma programmeerimiskeeled/moodulid nagu nt ROOT, mis on üles ehitatud osakeste füüsikale sobiva struktuuriga (andmeid saab lugeda osakese kaupa). Lisaks on veel mustmiljoon muud tarkvar või platvormi nagu Indico, EOS, SWAN, GEANT4. 
Markus tegi meile programmi alguses ka väikse viktoriini andmetöötluse teemal. Selle võitis, nagu kord ja kohus, meie arvutiteaduse tudengist juhendaja Karolin. Auhinnaks sai ta kiibi, mis oli olnud osa Higgsi bosoni leidmisest 2010.-2012. aastal.
Kusjuures oli väga inspireeriv kuulda Markust sellel teemal rääkimas. Fookus oli muidugi väga kindlal valdkonnal - programmeerimisel, ent ta tuletas ka ise meile meelde, et kõik lahendada vajavad probleemid ei asu arvutiteaduses ja innustas meid lihtsalt kirega misiganes valdkonnale pühenduma. 
Markuse kaudu saime külastade ka erinevaid arvutus-/serveriruume. Näiteks peahoone keldris oli tööl ruumitäis arvuteid, mis jooksutasid läbi ATLASE tarkvara, et leida võimalikke murekohti. Seesama tarkvara oli tööl aga märksa massiivsemas arvutiruumide klastris, mida meil õnnestus samuti näha. Korrus-korruse haaval oli ATLASe arvutuskeskus tikitud täis huugavaid ruume. Kusjuures kogu 100 meetrit sügavust oli ülevalt näha ja peab ütlema, et see oli vapustav, ent ka õõvastav. 
Nende korruste arvutite asemel kasutasime me aga vaid paari arvutit, mis meie eksperimendi kõrvalruumis asusid. Andmed läksid pilve ja meie saime neid seejärel oma läpakates analüüsida. Tegelikult jooksutasime enda arvutist aga mõnda CERN-i enda arvutit, kuna saime koodi jooksutamiseks kasutada eelnevalt mainitud SWAN platformi. Sellest hoolimata kulus ikka mitu minutit, et meie koodijupp lõpuni jookseks. Ja nii oli vaja oodata iga eksperimendi *run*iga. Nii saigi programmi lõpupäevadel inimesed hilisööni kokku kutsutud pelgalt selleks, et oodata kuni programm andmed läbi töötleb ja lõpptulemuse salvestab. 
